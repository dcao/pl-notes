---
aliases:
  - "Alias Analysis for Object-Oriented Programs"
tags:
  - reading
  - access-path
  - alias-analysis
  - allocation-site
  - call-graph
  - call-site
year: 2013
authors:
  - Sridharan, Manu
  - Chandra, Satish
  - Dolby, Julian
  - Fink, Stephen J.
  - Yahav, Eran
editors:
  - Clarke, Dave
  - Noble, James
  - Wrigstad, Tobias    
status: Todo
source: https://doi.org/10.1007/978-3-642-36946-9_8 
related:  
itemType: bookSection  
publisher: Springer  
location: Berlin, Heidelberg   
pages: 196-232  
ISBN: 978-3-642-36946-9
scheduled: 2024-07-27
---
> [!note] See also
> [This video lecture from Adrian Sampson for Cornell CS 6120](https://vod.video.cornell.edu/media/1_7ngps985) and [this page on Pointer Analysis for CS 701 at Wisconsin](https://pages.cs.wisc.edu/~fischer/cs701.f14/7.POINTER-ANALYSIS.html).

# Who cares? Motivating analyses

> [!note] See also
> This combines info from §2 of the paper and the CS 6120 lecture.

Anything that's "easy" with stack variables is difficult in the presence of (heap) pointers, without knowing something about **aliasing**: if two pointers actually point to the same value in memory at program point $p$, or if they point to different values.

We need to know about alias analysis when doing:

- **Eliminating dead stores to a pointer**: what if an alias reads the location later?
- **Propagating stores through loads**: normally we could do `*x = 4; *y = 6; 4 + *x` into `*y = 6; 4 + 4`. But if `x = y`, we can't do this!
- **[[ahoDragonBookMachineindependent2007#^9d6c9d|Loop-invariant code motion]]**: what if an alias modifies this value and it's not invariant in the loop condition?
- **Auto parallelization**: we can't be sure that two seem parallelizable procedures actually don't touch each other's state if their pointers alias
- **Calculating resource leaks**: often we want to do automated resource leak analysis in languages like Java.
 	- If we do `this.a = Resource(); t1 = this.a; free(t1)`, we need our analysis to know that the resource was freed!

Figuring out if two pointers will alias at any given point is ==undecidable==, and the answer might be *sometimes*! Thus, often we consider approximations that provide *may-alias analysis*: they tell us if two pointers *may* alias, but not if they *must*. However, this does guarantee that pointers *do not* alias!

In this paper, we examine two forms of alias analysis:

1. **Points-to analysis**, which is a *flow-insensitive* may-alias analysis.
2. **Access-path tracking**, which is a *flow-sensitive* must-alias analysis.

> [!note] On flow-sensitivity and -insensitivity
> In this note, we will discuss what it means to be flow-sensitive or -insensitive. However, it might also be useful to look at [[nielsonPrinciplesProgramAnalysis1999a#^70155c|Principles of Program Analysis 3: Constraint-based analysis]] and how they discuss flow-sensitivity in the context of control flow analysis.

# Points-to analysis

A **points-to** analysis is an over-approximation of the heap locations a program pointer (a variable or a pointer in a heap-allocated object, like an instance field) might point to. At some program point, given two variables $x$ and $y$, if they may potentially point to the same pointer according to this analysis—that is, the intersection between their set of possible heap locations is non-empty—then they *may* alias.

## Dataflow framework

Following the CS 6120 lecture, let's express a points-to analysis as a dataflow framework in the style of [[ahoDragonBookMachineindependent2007#Dataflow formally|Dragon Book 9: Machine-independent optimization]]. We define our dataflow framework as follows:

- The direction $D$ is **forward**.
- Our analysis value is a mapping from variables to heap locations they may point to. Thus, the domain $V$ is the set of mappings from variables to sets of heap locations: $\mathcal{P}(Var \to \mathcal{P}(Loc))$
- The meet operation is **union on variables and the locations they can refer to**.
- Our transfer function $f_{s}$ pattern matches on the statement $s$.
 	- `l = const K`: $f_{s}(x) = x[l \mapsto x(l) \cup \varnothing]$
 	- `l = alias y`: $f_{s}(x) = x[l \mapsto x(l) \cup x(y)]$
 	- `l = new y`: $f_{s}(x) = x[l \mapsto x(l) \cup l_{1}]$, where $l_{1}$ is a fresh location.

We say that two variables $x$ and $y$ *may alias* if, given dataflow analysis value $d$, $d(x) \cap d(y) \neq \varnothing$.

This analysis is **flow-insensitive**: the analysis value of statements doesn't actually depend on the order they're in! Indeed, because of how dataflow analysis iteratively propagates, reordering or repeating statements won't change the result of the analysis (even if it results in nonsense programs).

## Constraint-based framework

We can equivalently express this dataflow analysis in terms of constraints generated by inference rules:

| statement        | constraint                                                                                          |
| ---------------- | --------------------------------------------------------------------------------------------------- |
| `i: x = new T()` | $\{ o_{i} \} \subseteq pt(x)$                                                                       |
| `x = y`          | $pt(y) \subseteq pt(x)$                                                                             |
| `x = y.f`        |
$$
\begin{prooftree} \AXC{$o_{i} \in pt(y)$} \UIC{$pt(o_{i}.f) \subseteq pt(x)$} \end{prooftree}
$$ |
| `x.f = y`        |
$$
\begin{prooftree} \AXC{$o_{i} \in pt(x)$} \UIC{$pt(y) \subseteq pt(o_{i}.f)$} \end{prooftree}
$$ |
where $pt$ is the analysis value for some variable. The last two rules basically just do a "forall" with field access.

Some properties about this analysis:

- Like the above, it's **flow-insensitive**. They're saying equivalent things! $pt(y) \subseteq pt(x)$ is saying the same as $f_{s}(x) = x[l \mapsto x(l) \cup x(y)]$: the analysis for $x$ must include the analysis for $y$!
- It's **field-sensitive**. We can reason separately about each instance field of each abstract location. This is important for languages like Java (ugh lmao)
- It's **context-insensitive**. Every method call is must receive the same analysis, regardless of context. See the next section.

## Context sensitivity

Consider the following example program:

```java
id(p) { return p; }
o1 = new Object();
o2 = new Object();
a = id(o1);
b = id(o2);
```

With our current analysis, a function can only have one analysis, regardless of the calling context. Thus, we are forced to assume that `id` could potentially take both `o1` or `o2` as an argument. Thus, `id` can return either `o1` or `o2`, and `a` and `b` may alias.

In a **context-sensitive analysis**, we provide a distinct context for each call site. This process analyzes each call of `id` separately for each of its call sites, and can conclude that `id` only can return `o1` in its first call, and `o2` in its second call, meaning `a` and `b` can't alias!

> [!note] Parallels with $k$-CFAs and $m$-CFAs
> This is essentially an alternate formulation of $k$-CFAs and $m$-CFAs.
>
> As we go on, we'll be drawing parallels between this treatment of context-sensitivity and [[nielsonPrinciplesProgramAnalysis1999a#k-CFAs|that of control flow analysis of functional programs]].

Our formulation of this analysis assumes we're reaching statements inside a method $m$. We define $contexts(m)$ as the set of contexts arisen for all calls of $m$; we can think of $contexts(m)$ as the current environment in $k$/$m$-CFA land. Our analysis takes an *abstract pointer* $\langle x, c \rangle$ as an argument now, instead of just $x$, and the analysis value is a pair of pointer location and context, just like with $m$-CFAs (remember that with $m$-CFAs, the context environment *is* a context).

Our formulation of this analysis is generic over two functions, which specify a *context-sensitivity policy*:

- The *selector* function determines what context to use for a callee at a call site.
- The *heapSelector* function determines what context $c$ to store when we come across a new allocation.

![[Screenshot 2024-07-28 at 9.12.42 PM.png]]

Let's break this down.

- The first four rules just thread context information. `new` uses *heapSelector* to compute the stored context.
 - When $heapSelector(c) = c$, we have context-sensitive analysis.
 - When $heapSelector(c) = \varnothing$, we have context-insensitive analysis.
- The `Invoke` rule is a doozy lmao
 - The first two lines deal with virtual dispatch, calculating the true method.
 - The $argvals$ include analyses for `r` and `a_1` thru `a_n`.
 - The *selector* function builds our new context.
  - It takes the method being called $m'$, current context, call site $j$, and $argvals$, returning the new context for a method.
  - In a context-insensitive analysis, selector just returns $\varnothing$.
  - In $k$-CFA, *selector* returns $take(cons(j, c), k)$.
 - This new context must be in the contexts for $m'$.
 - The other rules propagate analyses from arguments to formal parameters.
  - Formal parameter must include arguments.
  - `x` must include return.
  - Remember the [[nielsonPrinciplesProgramAnalysis1999a#Constraint flow rule-of-thumb|constraint flow rule-of-thumb]]!

## Object sensitivity

Instead of distinguishing method calls by call strings, in **object-sensitive** analysis, we extend our context with `self` on every method call! The intuition is that this should be able to distinguish between identical operations performed on different `self` objects. Here, our context is no longer a list of call sites, but a set of locations—the different `self` objects that have had methods called on them in the process of getting to this expression:
$$
selector(\_{}, \_{}, \_{}, argvals) = \bigcup_{\langle o, c \rangle \in argvals[0]} cons(o, c)
$$
The precision of this analysis is incomparable to that of call-string-sensitive analysis. They're good at different things. People often combine them; use the other for static methods, this otherwise.

We can also do **type-sensitivity**, where we record the types of the enclosing class for the allocation site. This is kinda as accurate as object sensitivity, but is more scalable.

## Cartesian Product Algorithm

What if we don't limit our attention to just `self`, but look at all arguments? Indeed, since the analysis of each argument is a set, what if we look at the *cartesian product* between all of our arguments?

![[Screenshot 2024-07-28 at 9.46.29 PM.png]]
![[Screenshot 2024-07-28 at 9.46.38 PM.png]]

Originally used for type inference, since it's way less scalable for actual object values.

## Unification-based approaches

If we have equality instead of subset constraints, we can use fast union-find data structures to represent equal points-to sets. This works for C++ programs but not Java, since Java requires virtual dispatch.

> [!note]
> Another example of unification stuff. See [[semantic analysis]].

## Implementation

To implement this analysis, we [[repsProgramAnalysisGraph1998|express the analysis as a graph reachability problem]], similar to how we can solve other program analysis problems (e.g., [[nielsonPrinciplesProgramAnalysis1999a#^203nd2|similar to solving CFA constraints]]). Here, the graph $G$ has an edge $n \to n'$ iff one of the following holds:

- $n$ is an abstraction location $o_{i}$ representing a statement `x = new T()`, and $n'$ is `x`.
- $pt(n) \subseteq pt(n')$.

Since we want to essentially find what nodes are reachable from source nodes $o_{i}$, this is called a *transitive closure* problem. Transitive closure means—in the abstract—adding edges from nodes to transitively reachable nodes. Additionally, this is a *dynamic* transitive closure problem, since we can only add edges once existing edges have been traversed.

> [!note]
> This is an instance of

The actual algorithm doesn't involve adding edges for transitive closures, and instead mirrors the CFA graph-based analysis:

- Iterate through statements.
- When an edge hasn't been added, we add it and do *difference propagation* from source to target
 - Only add abstract locations where that reachability info hasn't propagated to successors
- Add successors to worklist where successors change

**This is $O(n^3)$.** We can do some small optimizations to make this faster too.

- Type filters
 - Label edges as requiring subtype of $T$ or exactly $T$.
 - `x = (T) y` requires for $y \to x$ a subtype of $T$.
 - Only add appropriately-typed objects to points-to sets.
 - Bit-vector intersection
- Cycle elimination
 - If we have `a = b; b = c; c = b;`, these will all have the same set. Collapse them to one node!
- Method-local state
 - For variables that don't point to method arguments, don't use global constraint system to compute them, and compute on-demand. Space savings!
 - Separate local state!

## How to implement better context sensitivity

How can we represent points-to sets and relevant structures in a more efficient way?

- Shared bit-vectors (Heintze, N.: Analysis of Large Code Bases: The Compile-Link-Analyze Model (Draft of November 12, 1999)
- Binary decision diagrams: representation for boolean functions. Imagine truth table with all variables. Each node is a variable, edge is either $0$ or $1$. At the end, node is $0$ or $1$. See [[ahoCompilersPrinciplesTechniques2007|Dragon]] §12.
- Limiting difference prop when adding edges
- **Demand-driven analysis**: only analyze where client requests it!

# Access-path tracking

But there are some cases where we want **must-alias** analyses! For example, let's look at the following example:

```java
File makeFile() {
 return new File();
}

File f = makeFile();
File g = makeFile();

if (...) {
 f.open();
}
```

Let's try to do state tracking. In points-to analysis, we have to represent *both* `f` and `g` with a single abstract object `A`, since they both call into `makeFile`. When we do `f.open`, `A` could be either closed or open, so we have to say `A` is both in an `open` state and in its `init`ial state. This called a *weak update*—it maintains the old state as part of the updated state. But now we can't really do any verification on this!

Note that context sensitivity doesn't really help here—both have the same method call stack!

We want to do **strong updates**, where we decisively choose the new state of the abstract object. We need to know that `f` **must** point to a different object than `g`.

This approach combines may- and must-alias info, made for typestate verification.

## Access paths

> [!danger]
> I'm not gonna reproduce the formal Greek here; this section just gives the general intuition for the technique.

An access path consists of all of `x.y. ... .z`.

First, we run flow-insensitive points-to analysis. Each abstract memory location in the points-to analysis—the mapped-to part of the analysis, not the variables or whatever—is referred to as an *instance key*.

Our analysis is flow-sensitive and context-sensitive. The analysis contains a bunch of *abstract program states*. Each of these states contains a bunch of tuples $(o, unique, AP_{m}, May, AP_{MN})$, where:

- $o$ is an instance key.
- $unique$ indicates if the allocation site has a single concrete live object
- $AP_{M}$ is all access paths that **must** point to $o$
 - Has a *length*—maximal length of access path in this set—and a *width*—maximum number of access paths
- $May$ is a bool, indicating if there are access paths (not in $AP_{M}$) that may point to $o$.
- $AP_{MN}$ is all access paths that **don't** point to $o$.
 - Also has *length* and *width*

They define *soundness* on tuples and states to ensure that tuples (in a state) follow these rules.

At each statement, for each input tuple, we transform it into a number of output tuples and union.

![[Screenshot 2024-07-29 at 11.26.34 AM.png]]

Important high-level overview:

- If we're allocating *and we've already seen this allocation before* (i.e., "$o$ = Stmt S"—it's already in our tuples and we're back here again), we return two tuples:
 - One for the new allocated object (we always do this regardless of if we've seen this allocation)
 - One for the previously allocated object assigned to that variable, which has been shadowed at this variable/access path by the new assignment.
  - This makes it potentially not unique—if there was one variable that refers to this object, it'd be zero now!
- For `v = null`, for all objects in the state, every path that starts with `v` should be moved to "doesn't point to," since it's `null` now!

Here's an example, where $\langle o, st \rangle$ denotes tuple $o$ with state $st$ (i.e., `init`, `open`, etc.).

![[Screenshot 2024-07-29 at 11.30.16 AM.png]]

We limit the length & width of or sets because:

- With recursion, access paths are boundless
- Loop-free code might inflate the sets way too large.

# Analyzing modern Java programs

## Points-to analysis difficulties

Points-to sucks for modern Java, because of **big libraries** and **reflection**.

With reflection, we can do meta-programming with string names of program constructs like classes or methods:

```java
class Factory {
 Object make(String x) {
  return Class.forName(x).newInstance();
 }
}
```

From type-level to term-level with strings. Reflection. Now we have no idea what kind of object is being allocated here! There are some mitigations but...

- We could track string constants, but people often do string concat and stuff.
- We could look for typecasts and use that to guide analysis
 - But often programs don't do typecasts! e.g., calling the reflection fn `Method.invoke()`
 - Or things made with reflection flow to interfaces which are implemented by many different types.

## Under-approximation

In contexts like bug finding, we actually don't need an over-approximate answer; instead, we can do **under-approximation** instead—return a subset of answers or locations that we know for sure are correct! Here, we don't guarantee that our results are all of the issues or aliases; but we guarantee that if we find something, it's definitely wrong.

For instance, we can use an under-approximation of the access path analysis to check for resource leaks. Here, our tuples are $(o, R, AP_{M})$, where $R$ is some resource type. Additionally, we only generate tuples when acquiring $R$, and delete tuples when releasing $R$. A memory leak corresponds to $(o, R, \{  \})$—a resource still exists at $o$, but there are no access paths that are guaranteed to point to $o$.

An example of a non-leaky code-snippet:

![[Screenshot 2024-07-29 at 1.56.39 PM.png]]

In the true case of the branch, there is no analysis, since `r` is a must-alias to a resource and so cannot be null. When we get to `release`, since `r` must alias, we release and get it to the end safely.

![[Screenshot 2024-07-29 at 2.02.41 PM.png]]

Here's an example of a leak, which occurs if the loop runs twice. On run 1, we acquire `R`, then go to the $\phi$ node, assigning $(p_{3}, R, \{ p_{2}, p_{3} \})$. Then, we *reacquire* R, creating a new tuple $(p_{3}, R, \{ p_{3} \})$ and killing $p_{3}$ from the previous tuple, yielding $(p_{3}, R, \{ p_{2} \})$. Then, when we get to $p_{2}$ again, we kill $p_{2}$ from that tuple, yielding $(p_{3}, R, \{  \})$. A leak!

For dealing with reflections, they also do **domain-specific reflection modeling**. By "domain," we mean "web frameworks" or that sort of thing. Application/programming domain.
